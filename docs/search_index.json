[["index.html", "Black Hills Experimental Forest Prescribed Fire Planning Chapter 1 Introduction", " Black Hills Experimental Forest Prescribed Fire Planning George Woolsey 2022-08-08 Chapter 1 Introduction My name is George Woolsey and I am currently employed by the United States Forest Service working with Dr. Mike Battaglia at the Rocky Mountain Research Station in Fort Collins, Colorado. In addition, I am pursuing a MS in Forest Sciences at Colorado State University (CSU). At CSU I am working with Dr. Wade Tinkham in the Forest Biometrics Lab. "],["objective.html", "Chapter 2 Objective", " Chapter 2 Objective The objective of this analysis is to describe the site conditions on the Black Hills Experimental Forest (North Dakota, USA) for planning future prescribed fire treatments. This analysis incorporates the spatial location of research plots and some of the measurements collected at those plots (e.g. Ritter et al. 2022). In ponderosa pine (Pinus ponderosa) forests, prescribed fires and wildfires burning under moderate conditions can effectively reduce fuel loading and restore the structures and complex spatial patterns that existed in these forests historically (Holden et al. 2007; Battaglia et al. 2008). In the ponderosa pine forests of the Black Hills, ladder fuels can develop quickly after a mechanical treatment if regeneration densities are not regulated. Prescribed fire can successfully maintain low regeneration densities following fuel treatments (Battaglia et al. 2008). In addition to reducing tree densities and surface fuel loads, prescribed fires can be used to improve nutrient cycling, increase forage plant production, and improve wildlife habitat (DeBano et al. 1998; Allen et al. 2002). "],["vector_data.html", "Chapter 3 Import Vector Data 3.1 National Forest Management data download 3.2 Load Research Plot data 3.3 Load Stem Map data 3.4 Load National Forests shapefile 3.5 Load Experimental Forests shapefile 3.6 Load FACTS Timber Harvests 3.7 Join Research Plot to Harvest 3.8 Join Stem Map to Research Plot &amp; Harvest 3.9 Map Harvests, Research Plots, Stem Map 3.10 Write Out Data", " Chapter 3 Import Vector Data # turn off the s2 processing ## https://stackoverflow.com/questions/68478179/how-to-resolve-spherical-geometry-failures-when-joining-spatial-data sf::sf_use_s2(FALSE) 3.1 National Forest Management data download The Forest Activity Tracking System (FACTS) database maintained by the U.S. Department of Agriculture, Forest Service (USFS) used to delineate georeferenced boundaries of forest harvest activities. # check for data and download zip_path &lt;- c( &quot;https://data.fs.usda.gov/geodata/edw/edw_resources/fc/S_USA.NFSLandUnit.gdb.zip&quot; # forests boundaries , &quot;https://data.fs.usda.gov/geodata/edw/edw_resources/fc/S_USA.Experimental_Area_Boundaries.gdb.zip&quot; # exp forest boundaries # , &quot;https://data.fs.usda.gov/geodata/edw/edw_resources/fc/S_USA.Activity_TimberHarvest.gdb.zip&quot; # Timber Harvests # , &quot;https://data.fs.usda.gov/geodata/edw/edw_resources/shp/S_USA.Activity_HazFuelTrt_PL.zip&quot; # Hazardous Fuel Treatment Reduction # , &quot;https://data.fs.usda.gov/geodata/edw/edw_resources/shp/S_USA.Activity_SilvTSI.zip&quot; # SilvTSI (Silviculture Timber Stand Improvement) # , &quot;https://data.fs.usda.gov/geodata/edw/edw_resources/shp/S_USA.Activity_SilvReforestation.zip&quot; # SilvReforestation # , &quot;https://edcintl.cr.usgs.gov/downloads/sciweb1/shared/MTBS_Fire/data/composite_data/burned_area_extent_shapefile/mtbs_perimeter_data.zip&quot; ) for (i in 1:length(zip_path)) { f_nm &lt;- paste0( &quot;../data/&quot; , str_split(zip_path[i], &quot;/&quot;, simplify = TRUE)[length(str_split(zip_path[i], &quot;/&quot;, simplify = TRUE))] ) fldr &lt;- paste0(gsub(&quot;.zip&quot;, &quot;&quot;, f_nm)) options(timeout = 60 * 15) if(file.exists(fldr) == FALSE){ # download data if(file.exists(f_nm) == FALSE){ download.file(zip_path[i], destfile = f_nm) }else{print(&quot;file already exists&quot;)} # unzip unzip(f_nm, overwrite=TRUE, exdir = fldr) file.remove(f_nm) }else{print(&quot;unzip already exists&quot;)} } 3.2 Load Research Plot data Ritter et al. 2022 established eleven, 100x100 m (1-ha), plots within mechanical treatment units. Measurements occurred during the summer of 2017, which represented 3 years post-treatment for small group retention treatment and 4 years post-treatment for free selection-off, free selection-On, and commercial thinning treatments. In the free selection-off treatments, overstory trees were included in the spacing guidelines for precommercial thinning treatment. In the free selection-on treatments, overstory trees were not included in the spacing guidelines for precommercial thinning treatments resulting in residual precommercial trees potentially growing under the crown of an overstory tree. # load shapefile research_plots &lt;- sf::st_read(&quot;../data/Black_Hills_StemMaps.shp&quot;) %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% rename_with(~ tolower( gsub(&quot; &quot;, &quot;_&quot;, str_trim(gsub(&quot;\\\\s+&quot;, &quot; &quot;, .x)) ) )) %&gt;% sf::st_buffer(dist = 50, endCapStyle = &quot;SQUARE&quot;) %&gt;% dplyr::mutate(area = sf::st_area(.)) #rename sf geom column names(research_plots)[names(research_plots)==tolower(attr(research_plots, &quot;sf_column&quot;))] = &quot;geometry&quot; sf::st_geometry(research_plots) = &quot;geometry&quot; # data structure of data research_plots %&gt;% glimpse() # plot does not uniquely identify record length(unique(research_plots$plot)) == nrow(research_plots) # create id research_plots &lt;- research_plots %&gt;% dplyr::group_by(plot) %&gt;% dplyr::mutate( plot_id = paste0(plot, &quot;_&quot;, as.character(dplyr::row_number())) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::relocate(plot_id) length(unique(research_plots$plot_id)) == nrow(research_plots) 3.3 Load Stem Map data Ritter et al. 2022 installed three plots in the commercial thin treatment and each of the two free selection treatments. Only two plots were installed in the small group retention treatment as it was smaller in area and was bisected by a powerline corridor that precluded the placement of more than two nonoverlapping plots. Each plot was subdivided into 16 25x25 m quadrats within which all live trees &gt;1.37 m tall had their x, y locations recorded. In addition to mapping their x, y location, all live trees were tagged and had their DBH, tree height (TH), compacted crown base height (CBH), crown width (CW), and species recorded. # load stem map shapefile stem_map &lt;- sf::st_read(&quot;../data/BHEF_stem_map.shp&quot;) %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% rename_with(~ tolower( gsub(&quot; &quot;, &quot;_&quot;, str_trim(gsub(&quot;\\\\s+&quot;, &quot; &quot;, .x)) ) )) %&gt;% sf::st_transform(crs = sf::st_crs(research_plots)) #rename sf geom column names(stem_map)[names(stem_map)==tolower(attr(stem_map, &quot;sf_column&quot;))] = &quot;geometry&quot; sf::st_geometry(stem_map) = &quot;geometry&quot; # data structure of stem map data stem_map %&gt;% glimpse() 3.4 Load National Forests shapefile # load forest boundary shapefile # extract file name f_path &lt;- paste0(&quot;../data&quot;, &quot;/&quot;, &quot;S_USA.NFSLandUnit.gdb&quot;, &quot;/&quot;) dta_nm &lt;- paste(f_path , list.files(f_path, pattern = &quot;\\\\.gdb$&quot;)[1] , sep = &quot;/&quot; ) lyr_nms &lt;- sf::st_layers(dsn = dta_nm)$name lyr &lt;- lyr_nms[grep(&quot;NFSLandUnit&quot;, lyr_nms)][1] # load in data forests &lt;- sf::st_read( dsn = dta_nm , layer = lyr , query = &quot;SELECT * FROM \\&quot;NFSLandUnit\\&quot; WHERE REGION NOT IN (&#39;08&#39;, &#39;09&#39;, &#39;10&#39;) AND NFSLANDUNITTYPE = &#39;National Forest&#39; &quot; ) %&gt;% rename_with(~ tolower( gsub(&quot; &quot;, &quot;_&quot;, str_trim(gsub(&quot;\\\\s+&quot;, &quot; &quot;, .x)) ) )) #rename sf geom column names(forests)[names(forests)==tolower(attr(forests, &quot;sf_column&quot;))] = &quot;geometry&quot; sf::st_geometry(forests) = &quot;geometry&quot; # transform forests &lt;- forests %&gt;% sf::st_transform(crs = sf::st_crs(research_plots)) #make BHNF only dataset forests_bhnf &lt;- forests %&gt;% filter(region == &quot;02&quot; &amp; nffid == &quot;0471&quot;) 3.5 Load Experimental Forests shapefile # load boundary shapefile # extract file name f_path &lt;- paste0(&quot;../data&quot;, &quot;/&quot;, &quot;S_USA.Experimental_Area_Boundaries.gdb&quot;, &quot;/&quot;) dta_nm &lt;- paste(f_path , list.files(f_path, pattern = &quot;\\\\.gdb$&quot;)[1] , sep = &quot;/&quot; ) lyr_nms &lt;- sf::st_layers(dsn = dta_nm)$name lyr &lt;- lyr_nms[grep(&quot;Experimental_Area_Boundaries&quot;, lyr_nms)][1] # load in data exp_forests &lt;- sf::st_read( dsn = dta_nm , layer = lyr ) %&gt;% rename_with(~ tolower( gsub(&quot; &quot;, &quot;_&quot;, str_trim(gsub(&quot;\\\\s+&quot;, &quot; &quot;, .x)) ) )) #rename sf geom column names(exp_forests)[names(exp_forests)==tolower(attr(exp_forests, &quot;sf_column&quot;))] = &quot;geometry&quot; sf::st_geometry(exp_forests) = &quot;geometry&quot; # transform exp_forests &lt;- exp_forests %&gt;% sf::st_transform(crs = sf::st_crs(research_plots)) # spatial join BHNF bhef_boundary &lt;- sf::st_intersection(forests_bhnf %&gt;% dplyr::select(nfslandunitid, nffid, nfslandunitname), exp_forests) 3.6 Load FACTS Timber Harvests Metadata file available here. Utilize data downloaded and created in Forest Management Impacts on Productivity project. This appendix includes a listing of all the active and inactive FACTS activity codes, as well as detailed descriptions of some of the codes. # load boundary shapefile harvests &lt;- sf::st_read(&quot;../data/harvests.gpkg&quot;) %&gt;% rename_with(~ tolower( gsub(&quot; &quot;, &quot;_&quot;, str_trim(gsub(&quot;\\\\s+&quot;, &quot; &quot;, .x)) ) )) #rename sf geom column names(harvests)[names(harvests)==tolower(attr(harvests, &quot;sf_column&quot;))] = &quot;geometry&quot; sf::st_geometry(harvests) = &quot;geometry&quot; # transform harvests &lt;- harvests %&gt;% sf::st_transform(crs = sf::st_crs(research_plots)) # spatial join BHEF # bhef_harvests &lt;- sf::st_intersection( # bhef_boundary %&gt;% # dplyr::select(name, station, hectares, lead_scientist) %&gt;% # dplyr::rename_with(~ paste0(&quot;exp_forest_&quot;, .), -geometry) %&gt;% # # there are some plots outside of BHEF boundary # sf::st_buffer(2500) # , harvests) bhef_harvests &lt;- sf::st_intersection( # there are some plots outside of BHEF boundary sf::st_union( bhef_boundary , sf::st_as_sfc(sf::st_bbox(research_plots)) %&gt;% sf::st_transform(crs = sf::st_crs(research_plots)) ) %&gt;% dplyr::select(geometry) , harvests) # filter for last 15 years bhef_harvests_l15 &lt;- bhef_harvests %&gt;% dplyr::filter(year_id &gt;= year(Sys.time()) - 15 ) %&gt;% dplyr::mutate(lab &lt;- paste0(treatment_type_grp, &quot; (&quot;, as.character(year_id), &quot;)&quot;)) 3.6.1 Harvests by treatment type # data by treatment type bhef_harvests_l15 %&gt;% sf::st_set_geometry(NULL) %&gt;% dplyr::group_by(activity_name) %&gt;% dplyr::summarise(n = n()) %&gt;% dplyr::arrange(desc(n)) %&gt;% ggplot(.) + geom_col(aes(y = reorder(activity_name, n), x = n, fill = n), width = 0.7) + geom_text( aes(y = reorder(activity_name, n), x =n, label = scales::comma(n, accuracy = 1)) , color = &quot;black&quot;, size = 4 , position = position_dodge(0.9) , hjust = -0.1 ) + labs( title = &quot;Number Harvests Completed by Treatment Type (last 15 years)&quot; , subtitle = &quot;within BHEF boundary and bounding box of research plot area&quot; ) + xlab(&quot;# Harvests&quot;) + ylab(&quot;Treatment&quot;) + scale_x_continuous(labels = scales::comma) + scale_fill_viridis_c(alpha = 0.7, option = &quot;cividis&quot;, direction = -1) + theme_bw() + theme( legend.position = &quot;none&quot; ) 3.7 Join Research Plot to Harvest # attach harvest data to research plots research_plots_harvests &lt;- sf::st_intersection( research_plots , bhef_harvests_l15 %&gt;% dplyr::select( activity_code , activity_name , treatment_type_grp , suid , date_compl , year_id ) %&gt;% # dplyr::filter(treatment_type_grp %in% c(&quot;Commercial Thinning&quot; # , &quot;Overstory Removal Cut&quot; # , &quot;Single-tree/Group Selection Cut&quot; # , &quot;Patch Clearcut&quot; # )) %&gt;% dplyr::rename_with(~ paste0(&quot;harvest_&quot;, .), -geometry) ) %&gt;% dplyr::mutate(harvest_plot_areamsq = as.numeric(sf::st_area(.))) %&gt;% sf::st_set_geometry(NULL) %&gt;% dplyr::group_by(plot_id) %&gt;% dplyr::arrange( plot_id , desc(harvest_plot_areamsq) , harvest_date_compl ) %&gt;% dplyr::select( plot_id , dplyr::starts_with(&quot;harvest_&quot;) ) %&gt;% dplyr::mutate( row_n = dplyr::row_number() ) %&gt;% dplyr::ungroup() %&gt;% tidyr::pivot_wider( id_cols = plot_id , names_from = row_n , values_from = !c(plot_id, row_n) , names_sep = &quot;_&quot; ) # join to spatial data research_plots &lt;- research_plots %&gt;% left_join(research_plots_harvests, by = c(&quot;plot_id&quot;=&quot;plot_id&quot;)) remove(research_plots_harvests) 3.8 Join Stem Map to Research Plot &amp; Harvest # attach harvest data to stem map stem_map_harvests &lt;- sf::st_intersection( stem_map , bhef_harvests_l15 %&gt;% dplyr::select( activity_code , activity_name , treatment_type_grp , suid , date_compl , year_id ) %&gt;% dplyr::rename_with(~ paste0(&quot;harvest_&quot;, .), -geometry) ) %&gt;% sf::st_set_geometry(NULL) %&gt;% dplyr::group_by(uidtree) %&gt;% dplyr::arrange( uidtree , harvest_date_compl ) %&gt;% dplyr::select( uidtree , dplyr::starts_with(&quot;harvest_&quot;) ) %&gt;% dplyr::mutate( row_n = dplyr::row_number() ) %&gt;% dplyr::ungroup() %&gt;% tidyr::pivot_wider( id_cols = uidtree , names_from = row_n , values_from = !c(uidtree, row_n) , names_sep = &quot;_&quot; ) # join to spatial data stem_map &lt;- stem_map %&gt;% left_join(stem_map_harvests, by = c(&quot;uidtree&quot;=&quot;uidtree&quot;)) # join to research plot data temp_stem_map &lt;- sf::st_intersection( stem_map %&gt;% dplyr::select(uidtree) , research_plots %&gt;% dplyr::select(plot_id, trt, harvest_activity_name_1, harvest_year_id_1, harvest_treatment_type_grp_1) %&gt;% dplyr::rename_with(~ paste0(&quot;rplot_&quot;, .), -geometry) ) %&gt;% sf::st_set_geometry(NULL) stem_map &lt;- stem_map %&gt;% left_join(temp_stem_map, by = c(&quot;uidtree&quot;=&quot;uidtree&quot;)) remove(list = c(&quot;stem_map_harvests&quot;, &quot;temp_stem_map&quot;)) 3.8.1 Stem Map Descriptive statistics. # descriptive stats kable(stem_map %&gt;% sf::st_set_geometry(NULL) %&gt;% dplyr::group_by( unit , harvest_activity_name_1 ) %&gt;% dplyr::summarise( # plots = dplyr::n_distinct(plot) trees = dplyr::n_distinct(uidtree) , min_DBHin = min(dbhin) , max_DBHin = max(dbhin) , mean_DBHin = mean(dbhin) , QMDin = sqrt( sum(dbhin*dbhin) / n() ) , min_HTft = min(heightft) , max_HTft = max(heightft) , mean_HTft = mean(heightft) , stdev_HTft = sd(heightft) ) %&gt;% dplyr::arrange(unit, desc(trees)) , format = &quot;html&quot; , caption = &quot;Tree Measurement Descriptive Statistics by Unit &amp; Treatment&quot; , digits = 1 , col.names = c( &quot;unit&quot; , &quot;treatment&quot; # , &quot;# plots&quot; , &quot;# trees&quot; , &quot;min&quot; , &quot;max&quot; , &quot;mean&quot; , &quot;QMD&quot; , &quot;min&quot; , &quot;max&quot; , &quot;mean&quot; , &quot;st.dev.&quot; ) , align=rep(&#39;c&#39;, 5) ) %&gt;% # kable_classic() %&gt;% add_header_above(c(&quot; &quot; = 3, &quot;DBH (in.)&quot; = 3, &quot;QMD (in.)&quot; = 1, &quot;Height (ft.)&quot; = 4)) %&gt;% kable_material(c(&quot;striped&quot;, &quot;hover&quot;)) %&gt;% # column_spec(., 2, width = &quot;20em&quot;) %&gt;% kable_styling(font_size = 11) 3.9 Map Harvests, Research Plots, Stem Map # make map # different background map types: https://leaflet-extras.github.io/leaflet-providers/preview/ # names(leaflet.providers::providers_loaded()$providers) mapviewOptions(homebutton = FALSE, basemaps = c(&quot;Esri&quot;)) # map mapview(bhef_boundary , color = &quot;black&quot; , lwd = 3 , alpha.regions = 0 , label = FALSE , legend = FALSE , popup = FALSE ) + mapview(bhef_harvests_l15 , zcol = &quot;treatment_type_grp&quot; , col.regions = viridis::viridis(n=length(unique(bhef_harvests_l15$treatment_type_grp))) , alpha.regions = 0.6 , label = c(&quot;lab&quot;) , legend = FALSE , popup = popupTable( bhef_harvests_l15 , zcol = c( &quot;year_id&quot; , &quot;treatment_type_grp&quot; , &quot;activity_name&quot; ) , row.numbers = FALSE , feature.id = FALSE ) ) + mapview(research_plots , zcol = &quot;trt&quot; , col.regions = viridis::mako(n=length(unique(research_plots$trt)), direction = -1) , lwd = 2 , col = &quot;gray90&quot; , alpha.regions = 0.8 , label = c(&quot;trt&quot;) , legend = FALSE , popup = popupTable( research_plots , zcol = c( &quot;plot&quot; , &quot;trt&quot; , &quot;harvest_activity_name_1&quot; , &quot;harvest_year_id_1&quot; ) , row.numbers = FALSE , feature.id = FALSE ) ) + mapview(stem_map , zcol = &quot;unit&quot; , col.regions = viridis::turbo(n=length(unique(stem_map$unit)), alpha = 0.8) # RColorBrewer::brewer.pal(n = length(unique(stem_map$unit)), name = &quot;RdYlBu&quot;) , cex = 3.5 , label = c(&quot;unit&quot;) , legend = FALSE , popup = popupTable( stem_map , zcol = c( &quot;unit&quot; , &quot;plot&quot; , &quot;species&quot; , &quot;tag&quot; , &quot;heightft&quot; , &quot;dbhin&quot; , &quot;harvest_activity_name_1&quot; , &quot;harvest_year_id_1&quot; ) , row.numbers = FALSE , feature.id = FALSE ) ) Note, only harvests in last 15 years shown 3.10 Write Out Data # save cleaned data for reading to R later sf::st_write(forests_bhnf, &quot;../data/forests_bhnf.gpkg&quot;, append = FALSE) sf::st_write(bhef_boundary, &quot;../data/bhef_boundary.gpkg&quot;, append = FALSE) sf::st_write(bhef_harvests, &quot;../data/bhef_harvests.gpkg&quot;, append = FALSE) sf::st_write(research_plots, &quot;../data/research_plots.gpkg&quot;, append = FALSE) sf::st_write(stem_map, &quot;../data/stem_map.gpkg&quot;, append = FALSE) "],["stem_map.html", "Chapter 4 Analyze Lidar Data 4.1 Download Data From Natl Map 4.2 Load Vector Data 4.3 Load Elevation Data 4.4 Load Lidar Data 4.5 Map Harvests, Research Plots, Stem Map", " Chapter 4 Analyze Lidar Data # turn off the s2 processing ## https://stackoverflow.com/questions/68478179/how-to-resolve-spherical-geometry-failures-when-joining-spatial-data sf::sf_use_s2(FALSE) 4.1 Download Data From Natl Map The USGS National Map was used to obtain a list of file download links for Elevation Source Data (3DEP) - Lidar, IfSAR data available marked as Lidar Point Cloud (LPC). This download file list was placed in the data folder where the code below utilizes it to download data. The thumbnail option in the Natl Map was used to determine that the Fugro data will suffice to cover the BHEF area. Also, downloaded NAIP imagery while had ROI drawn in Natl Map. ####################################################### ####################################################### # lidar data ####################################################### ####################################################### # open download text file urls &lt;- read.delim(&quot;../data/usgs_lidar_data.txt&quot;, header = FALSE) %&gt;% dplyr::rename(url_path = 1) %&gt;% dplyr::filter(grepl(&quot;FUGRO&quot;, toupper(url_path)) == TRUE) %&gt;% dplyr::mutate( orig_fname = word(gsub(&quot;/&quot;, &quot; &quot;, url_path), -1) , fname_sans_typ = gsub(&quot;.laz&quot;, &quot;&quot;, orig_fname) ) # create parent directory for data hey_dir &lt;- &quot;../data/lidar/&quot; if(dir.exists(hey_dir)==FALSE){ dir.create(hey_dir) } #loop through to download lidar data for(i in 1:nrow(urls)){ # set up names f_nm &lt;- paste0(hey_dir , urls$orig_fname[i] ) options(timeout = 60 * 15) ######################## ## download and unzip ######################## if(file.exists(f_nm)==FALSE){ # download download.file(urls$url_path[i], destfile = f_nm) }else{ print(paste0(f_nm, &quot; file already exists&quot;)) } } NAIP imagery was downloaded from the USGS Earth Explorer. ## Load NAIP Imagery # load with stars tifs &lt;- list.files(&quot;../data/naip/&quot;, pattern = &quot;\\\\.tif$&quot;, full.names = TRUE) # x &lt;- stars::read_stars(imgs[1]) x &lt;- stars::read_stars(tifs[1]) plot(x %&gt;% dplyr::slice(band, 1), axes = TRUE) r = stars::st_rgb(x[,,,c(1:3)], use_alpha = FALSE) # ggplot() + # stars::geom_stars(data = r) + # scale_fill_identity() 4.2 Load Vector Data Spatial data was loaded and cleaned in prior chapter. # save cleaned data for reading to R later forests_bhnf &lt;- sf::st_read(&quot;../data/forests_bhnf.gpkg&quot;) bhef_boundary &lt;- sf::st_read(&quot;../data/bhef_boundary.gpkg&quot;) bhef_harvests &lt;- sf::st_read(&quot;../data/bhef_harvests.gpkg&quot;) research_plots &lt;- sf::st_read(&quot;../data/research_plots.gpkg&quot;) stem_map &lt;- sf::st_read(&quot;../data/stem_map.gpkg&quot;) 4.3 Load Elevation Data Using elevatr::get_elev_raster to get a digital elevation model (DEM) raster (~6.8m resolution). # read in elevation data # z =14 is highest resolution (~6.8m) if(file.exists(&quot;../data/bhef_elev.tif&quot;) == FALSE){ elev &lt;- elevatr::get_elev_raster(bhef_boundary, z = 14) # sf::st_crs(elev) == sf::st_crs(bhef_boundary) bhef_elev &lt;- stars::st_as_stars(elev) # sf::st_transform(crs = sf::st_crs(bhef_boundary)) # save stars::write_stars(bhef_elev, &quot;../data/bhef_elev.tif&quot;, append = FALSE) }else{ bhef_elev &lt;- stars::read_stars(&quot;../data/bhef_elev.tif&quot;) } # plot ggplot() + stars::geom_stars(data = bhef_elev[bhef_boundary]) + scale_fill_viridis_c(option = &quot;cividis&quot;, alpha = 0.9, na.value = &quot;transparent&quot;) + labs( title = &quot;BHEF Elevation Map&quot; , subtitle = sf::st_crs(bhef_elev)$input ) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + theme_bw() + theme( axis.text = element_text(size = 8) # , panel.grid = element_blank() , panel.border = element_blank() ) + guides( fill = guide_legend(title=&quot;Elev. (m)&quot;) ) 4.4 Load Lidar Data Use the lidR package for manipulating and visualizing point cloud data. See the very helpful book by Roussel, J.R., Goodbody, T.R.H., and Tompalski P. (2021) for more information. # list laz files lazs &lt;- list.files(&quot;../data/lidar/&quot;, pattern = &quot;\\\\.laz$&quot;, full.names = TRUE) # change projection of DEM # # creating a new regular grid in a new CRS # newgrid &lt;- bhef_boundary %&gt;% # sf::st_transform(crs = sf::st_crs( lidR::readLAS(lazs[1], select = &quot;xyz&quot;) )) %&gt;% # sf::st_bbox() %&gt;% # stars::st_as_stars() # # set up old grid to warp back # oldgrid &lt;- bhef_boundary %&gt;% # sf::st_bbox() %&gt;% # stars::st_as_stars() # # warping the old raster to the new grid # bhef_elev_reproj &lt;- bhef_elev %&gt;% # stars::st_warp(newgrid) bhef_elev_reproj &lt;- bhef_elev %&gt;% stars::st_warp(crs = sf::st_crs( lidR::readLAS(lazs[1], select = &quot;xyz&quot;) )) ###################################################### # read laz files ###################################################### # If several files are read at once the returned LAS object is considered as one LAS file. # las &lt;- lidR::readLAS(c(lazs[1],lazs[2]), select = &quot;xyz&quot;) # load XYZ only las &lt;- lidR::readLAS(lazs[2], select = &quot;xyz&quot;) # load XYZ only # lidR::las_check(las) # remove duplicate points las &lt;- lidR::filter_duplicates(las) # lidR::las_check(las) # summary(las$Z) # sf::st_crs(las) # temp_plot &lt;- plot(las, color = &quot;Z&quot;, breaks = &quot;quantile&quot;, bg = &quot;white&quot;) # temp_plot # # add_treetops3d(temp_plot, tree_tops) ###################################################### # remove outliers ###################################################### # Use Statistical Outliers Removal (SOR) # k = number of neighbors # m = multiplier in : avg distance + m * std deviation las &lt;- lidR::classify_noise(las, sor(k = 15, m = 7)) # plot(las, color = &quot;Classification&quot;, bg = &quot;white&quot;, size = 3) # Remove outliers using filter_poi() las &lt;- lidR::filter_poi(las, Classification != LASNOISE) # plot(las, color = &quot;Z&quot;, breaks = &quot;quantile&quot;, bg = &quot;white&quot;) # #repeat process with Isolated Voxels Filter IVF # las &lt;- lidR::classify_noise(las, ivf(res = 5, n = 6)) # # plot(las, color = &quot;Classification&quot;, bg = &quot;white&quot;, size = 3) # # Remove outliers using lidR::filter_poi() # las &lt;- lidR::filter_poi(las, Classification != LASNOISE) # plot(las, color = &quot;Z&quot;, breaks = &quot;quantile&quot;, bg = &quot;white&quot;) # ##################################################### # Ground classification # !!!!!!!!!!!!!!!!!!!!!!!!!! This is computationally intensive :&#39;( # ##################################################### # ################################################## # Progressive Morphological Filter The implementation of PMF algorithm in lidR # is based on the method described in Zhang et al. (2003) # ################################################## # # # b numeric. This is the parameter b in Zhang et al. (2003) (eq. 4 and 5). # # # dh0 numeric. This is dh0 in Zhang et al. (2003) (eq. 7). # # # dhmax numeric. This is dhmax in Zhang et al. (2003) (eq. 7). # # # s numeric. This is s in Zhang et al. (2003) (eq. 7). # # # max_ws numeric. Maximum window size to be used in filtering ground returns. This # # # limits the number of windows created. # # # exp logical. The window size can be increased linearly or exponentially (eq. 4 or 5). # # lidR::util_makeZhangParam( # # b = 2, # # dh0 = 0.2, # # dhmax = 210, # # s = 1.2, # # max_ws = 20, # # exp = FALSE # # ) # las &lt;- lidR::classify_ground(las, algorithm = pmf( # ws = lidR::util_makeZhangParam()$ws # , th = lidR::util_makeZhangParam()$th # ) # ) 4.4.1 Height normalization using DEM ###################################################### # Height normalization using DEM # could create own DEM with lidar data ... # but will use out of the box product for now ###################################################### # subtract DEM from lidar returns nlas &lt;- las - bhef_elev_reproj # correct for below ground returns nlas@data$Z &lt;- ifelse( ceiling(nlas@data$Z) == 0 | floor(nlas@data$Z) == 0 | nlas@data$Z &lt;= 0 , 0, nlas@data$Z ) # nlas &lt;- filter_poi(nlas, Z &gt;= 0) # remove below ground points nlas@data$Z &lt;- ifelse(nlas@data$Z &lt;= 0, 0, nlas@data$Z) # update classification nlas@data$Classification &lt;- ifelse(nlas@data$Z==0, 2, nlas@data$Classification) # filter out top 0.2% heights nlas &lt;- filter_poi(nlas, Z &lt;= stats::quantile((nlas@data %&gt;% dplyr::filter(Classification==1))$Z, 0.998)) # plot(nlas, color = &quot;Z&quot;, breaks = &quot;pretty&quot;, bg = &quot;white&quot;) # summary(nlas$Z) # table(nlas$Classification) # ###################################################### # # Height normalization using point cloud interpolation # # !!!!!! must run ground classification above first # ###################################################### # # point cloud normalization using interpolation # nlas &lt;- normalize_height(las, knnidw()) # # plot(nlas, color = &quot;Z&quot;, breaks = &quot;pretty&quot;, bg = &quot;white&quot;) # # plot(lidR::filter_ground(nlas), color = &quot;Classification&quot;, bg = &quot;white&quot;) # # summary(nlas$Z) # # table(nlas$Classification) # descriptive stats kable(nlas@data %&gt;% dplyr::group_by( Classification ) %&gt;% dplyr::summarise( # plots = dplyr::n_distinct(plot) points = dplyr::n() , min_z = min(Z) , max_z = max(Z) , mean_z = mean(Z) , median_z = median(Z) , stdev_z = sd(Z) ) %&gt;% dplyr::arrange(Classification) %&gt;% dplyr::mutate( Classification = dplyr::case_when( Classification == 1 ~ &quot;Surface&quot; , Classification == 2 ~ &quot;Ground&quot; , TRUE ~ &quot;Other&quot; ) ) , format = &quot;html&quot; , caption = &quot;Point Cloud Summary Statistics for Return Height (Z)&quot; , digits = 1 , col.names = c( &quot;Classification&quot; , &quot;points&quot; , &quot;min&quot; , &quot;max&quot; , &quot;mean&quot; , &quot;median&quot; , &quot;st.dev.&quot; ) , align=rep(&#39;c&#39;, 5) ) %&gt;% # kable_classic() %&gt;% add_header_above(c(&quot; &quot; = 2, &quot;Point Return Height (m)&quot; = 5)) %&gt;% kable_material(c(&quot;striped&quot;, &quot;hover&quot;)) %&gt;% # column_spec(., 2, width = &quot;20em&quot;) %&gt;% kable_styling(font_size = 11) # ggplot() + geom_histogram(data = (nlas@data %&gt;% dplyr::filter(Classification == 1)), aes(Z), binwidth = 1) 4.4.2 Canopy Height model ###################################################### # Canopy Height model ###################################################### # Points-to-raster algorithm with a resolution of 1 meter chm &lt;- lidR::rasterize_canopy( nlas , res = 1 # for each pixel of the output raster the function attributes the height of the highest point found , p2r(subcircle = 0.0 # , na.fill = tin() , na.fill = knnidw( k = 10 , p = 2 , rmax = 5 ) ) , pkg = &quot;terra&quot; ) # smooth chm pixels with median value in 3x3 matrix kernel &lt;- matrix(1,3,3) chm_smooth &lt;- terra::focal(chm, w = kernel, fun = median, na.rm = TRUE) %&gt;% stars::st_as_stars() %&gt;% stars::st_warp(crs = sf::st_crs(bhef_boundary)) # %&gt;% # sf::st_transform(crs = sf::st_crs(bhef_boundary)) # non smoothed chm &lt;- chm %&gt;% stars::st_as_stars() %&gt;% stars::st_warp(crs = sf::st_crs(bhef_boundary)) # plot ggplot() + stars::geom_stars(data = chm_smooth) + geom_sf(data = sf::st_crop(bhef_boundary, sf::st_bbox(chm_smooth)), alpha = 0, lwd = 0) + scale_fill_viridis_c(option = &quot;mako&quot;, alpha = 0.9) + labs( title = &quot;BHEF Canopy Height Model&quot; , subtitle = sf::st_crs(chm_smooth)$input ) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + theme_bw() + theme( # legend.position = &quot;bottom&quot; # , legend.direction = &quot;horizontal&quot; axis.text = element_text(size = 8) # , panel.grid = element_blank() , panel.border = element_blank() ) + guides( fill = guide_legend(title=&quot;Hgt. (m)&quot;) ) 4.4.3 Individual Tree Detection (ITD) ###################################################### # Individual Tree Detection (ITD) ###################################################### # local maximum filtering (LMF) with variable window size # points below 2 m will equate to a window size of 3 m, # while points above 20 meters equate to a window size of 5 m. # Anything between 2 and 20 meter will have a non-linear relationship # define variable window function ws_fn &lt;- function(x) { y &lt;- 2.6 * (-(exp(-0.08*(x-2)) - 1)) + 3 y[x &lt; 2] &lt;- 3 y[x &gt; 20] &lt;- 5 return(y) } # ITD on CHM tree_tops &lt;- lidR::locate_trees(chm_smooth, lmf(ws = ws_fn)) %&gt;% # create classes based on Steel et al. 2021 dplyr::mutate( tree_class = dplyr::case_when( Z &gt; 8 ~ 3 # canopy , Z &gt;= 2 ~ 2 # subcanopy , Z &gt;= 1 ~ 1 # understory , TRUE ~ 0 # ground ) ) # plot ggplot() + stars::geom_stars(data = chm_smooth) + geom_sf(data = tree_tops, color = viridis::viridis(n=1, direction = -1), alpha = 0.7, shape = &quot;.&quot;) + scale_fill_viridis_c(option = &quot;mako&quot;, alpha = 0.9) + labs( title = &quot;BHEF Canopy Height Model with Tree Tops Identified (yellow)&quot; , subtitle = sf::st_crs(chm_smooth)$input ) + theme_bw() + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + theme( axis.text = element_text(size = 8) # , panel.grid = element_blank() , panel.border = element_blank() ) + guides( fill = guide_legend(title=&quot;Hgt. (m)&quot;) ) # hey_plot &lt;- plot(nlas, color = &quot;Z&quot;, breaks = &quot;pretty&quot;, bg = &quot;white&quot;) # add_treetops3d(hey_plot, tree_tops &lt;- lidR::locate_trees(chm_smooth, lmf(ws = ws_fn)), col = &quot;black&quot;) # ?lidR::pixel_metrics() 4.4.3.1 Distribution of Tree Top Heights ###################################################### # height range of tree tops ###################################################### tree_tops %&gt;% sf::st_set_geometry(NULL) %&gt;% dplyr::mutate(height_ceil = ceiling(Z)) %&gt;% dplyr::group_by(height_ceil) %&gt;% dplyr::summarise(n = n()) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( pct_tot = n / sum(n) ) %&gt;% ggplot(.) + # geom_col(aes(x = height_ceil, y = n, fill = n)) + geom_bar(aes(x = height_ceil, y = pct_tot, fill = n), color = &quot;gray25&quot;, stat = &quot;identity&quot;) + scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) + scale_x_continuous(breaks = seq(min(tree_tops$Z), max(tree_tops$Z)+1, 1))+ scale_fill_viridis_c(alpha = 0.9, option = &quot;mako&quot;, direction = -1) + labs( title = &quot;Distribution of Tree Top Heights (m)&quot; ) + xlab(&quot;Tree Height (m) Bin&quot;) + ylab(&quot;% Tree tops&quot;) + theme_bw() + theme( legend.position=&quot;none&quot; ) 4.4.4 Individual Tree Segmentation (ITS) Segment the canopy height model raster grid as individual trees. Create a vector representation of tree groupings and summary statistics of height for each group. ###################################################### # Individual Tree Segmentation (ITS) ###################################################### # implements an algorithm for tree segmentation based on # Dalponte and Coomes (2016) algorithm (see reference). # This is a seeds + growing region algorithm. algo &lt;- lidR::dalponte2016(chm = chm_smooth, treetops = tree_tops, th_tree = 2) crowns_st &lt;- algo() # quick plot plot(crowns_st, col = lidR::pastel.colors(200), main = &quot;Individual Tree Crowns&quot;) # transform crowns stars object to vector data crowns_sf &lt;- crowns_st %&gt;% # convert to vector data and merge polygons with identical pixel values sf::st_as_sf(as_points = FALSE, merge = TRUE) %&gt;% # transform to same crs as rest of data sf::st_transform(crs = st_crs(bhef_boundary)) %&gt;% dplyr::mutate( tree_id = values , crown_area = sf::st_area(.) ) %&gt;% dplyr::relocate(tree_id, crown_area) %&gt;% dplyr::select(tree_id, crown_area) %&gt;% sf::st_set_precision(1e7) %&gt;% sf::st_make_valid(.) %&gt;% dplyr::filter(sf::st_is_valid(.)) # combine crown groups crowns_group &lt;- sf::st_cast( sf::st_union(crowns_sf) , &quot;POLYGON&quot;) # quick plot plot(crowns_group, col = lidR::pastel.colors(200), main = &quot;Tree Crown Groups&quot;) #create id column crowns_group &lt;- crowns_group %&gt;% merge(., data.frame(geo_type = sf::st_geometry_type(crowns_group)), by.x=0, by.y=0, all.x=TRUE) %&gt;% dplyr::mutate(crown_group_id = as.numeric(as.factor(Row.names))) %&gt;% dplyr::select(-c(geo_type, Row.names)) %&gt;% dplyr::relocate(crown_group_id) %&gt;% sf::st_as_sf(., sf_column_name = &quot;geometry&quot;, crs = sf::st_crs(bhef_boundary)) # join back to individual tree crowns and summarize crowns_group_sum &lt;- sf::st_intersection(tree_tops, crowns_group) %&gt;% # if need to keep group at tree level... break here sf::st_set_geometry(NULL) %&gt;% dplyr::group_by(crown_group_id) %&gt;% dplyr::summarise( count_trees = dplyr::n_distinct(treeID) , min_hgt_m = min(Z, na.rm = TRUE) , max_hgt_m = max(Z, na.rm = TRUE) , mean_hgt_m = mean(Z, na.rm = TRUE) , median_hgt_m = median(Z, na.rm = TRUE) , median_hgt_m = median(Z, na.rm = TRUE) , quant10_hgt_m = as.numeric( quantile(Z, probs = .10, na.rm = TRUE) ) , quant25_hgt_m = as.numeric( quantile(Z, probs = .25, na.rm = TRUE) ) , quant50_hgt_m = as.numeric( quantile(Z, probs = .50, na.rm = TRUE) ) , quant75_hgt_m = as.numeric( quantile(Z, probs = .75, na.rm = TRUE) ) , quant90_hgt_m = as.numeric( quantile(Z, probs = .90, na.rm = TRUE) ) , count_trees_canopy = sum(ifelse(tree_class == 3, 1, 0), na.rm = TRUE) , count_trees_subcanopy = sum(ifelse(tree_class == 2, 1, 0), na.rm = TRUE) , count_trees_understory = sum(ifelse(tree_class == 1, 1, 0), na.rm = TRUE) , count_trees_ground = sum(ifelse(tree_class == 0, 1, 0), na.rm = TRUE) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::arrange(crown_group_id) %&gt;% dplyr::mutate( crown_group_class = dplyr::case_when( count_trees == 1 ~ &quot;Individual Tree&quot; , count_trees &lt;= 10 &amp; count_trees_canopy/count_trees &gt;= .75 ~ &quot;Small Group - Canopy&quot; , count_trees &lt;= 10 &amp; count_trees_subcanopy/count_trees &gt;= .75 ~ &quot;Small Group - Subcanopy&quot; , count_trees &lt;= 10 ~ &quot;Small Group - Mixed&quot; , count_trees &lt;= 40 &amp; count_trees_canopy/count_trees &gt;= .75 ~ &quot;Medium Group - Canopy&quot; , count_trees &lt;= 40 &amp; count_trees_subcanopy/count_trees &gt;= .75 ~ &quot;Medium Group - Subcanopy&quot; , count_trees &lt;= 40 ~ &quot;Medium Group - Mixed&quot; , count_trees_canopy/count_trees &gt;= .75 ~ &quot;Continuous - Canopy&quot; , count_trees_subcanopy/count_trees &gt;= .75 ~ &quot;Continuous - Subcanopy&quot; , TRUE ~ &quot;Continuous - Mixed&quot; ) ) #attach summary statistics to spatial crown groups crowns_group &lt;- crowns_group %&gt;% dplyr::left_join(crowns_group_sum, by = c(&quot;crown_group_id&quot; = &quot;crown_group_id&quot;)) %&gt;% dplyr::mutate( crown_group_area_ha = as.numeric(sf::st_area(.)) / 10000 , trees_per_ha = count_trees / crown_group_area_ha ) 4.4.5 Plot Crown Groups # plot ggplot() + geom_sf(data = crowns_group, aes(fill = crown_group_class), lwd = 0) + scale_fill_viridis_d(option = &quot;turbo&quot;, alpha = 0.9) + labs( title = &quot;BHEF Crown Groups&quot; , subtitle = sf::st_crs(crowns_group)$input ) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + theme_bw() + theme( legend.position = &quot;bottom&quot; , legend.title = element_blank() , axis.text = element_text(size = 8) # , panel.grid = element_blank() , panel.border = element_blank() ) 4.5 Map Harvests, Research Plots, Stem Map # make map # different background map types: https://leaflet-extras.github.io/leaflet-providers/preview/ # names(leaflet.providers::providers_loaded()$providers) mapviewOptions(homebutton = FALSE, basemaps = c(&quot;Esri&quot;)) # map mapview(bhef_boundary , color = &quot;black&quot; , lwd = 3 , alpha.regions = 0 , label = FALSE , legend = FALSE , popup = FALSE ) + mapview(bhef_harvests_l15 , zcol = &quot;treatment_type_grp&quot; , col.regions = viridis::viridis(n=length(unique(bhef_harvests_l15$treatment_type_grp))) , alpha.regions = 0.6 , label = c(&quot;lab&quot;) , legend = FALSE , popup = popupTable( bhef_harvests_l15 , zcol = c( &quot;year_id&quot; , &quot;treatment_type_grp&quot; , &quot;activity_name&quot; ) , row.numbers = FALSE , feature.id = FALSE ) ) + mapview(research_plots , zcol = &quot;trt&quot; , col.regions = viridis::mako(n=length(unique(research_plots$trt)), direction = -1) , lwd = 2 , col = &quot;gray90&quot; , alpha.regions = 0.8 , label = c(&quot;trt&quot;) , legend = FALSE , popup = popupTable( research_plots , zcol = c( &quot;plot&quot; , &quot;trt&quot; , &quot;harvest_activity_name_1&quot; , &quot;harvest_year_id_1&quot; ) , row.numbers = FALSE , feature.id = FALSE ) ) + mapview(stem_map , zcol = &quot;unit&quot; , col.regions = viridis::turbo(n=length(unique(stem_map$unit)), alpha = 0.8) # RColorBrewer::brewer.pal(n = length(unique(stem_map$unit)), name = &quot;RdYlBu&quot;) , cex = 3.5 , label = c(&quot;unit&quot;) , legend = FALSE , popup = popupTable( stem_map , zcol = c( &quot;unit&quot; , &quot;plot&quot; , &quot;species&quot; , &quot;tag&quot; , &quot;heightft&quot; , &quot;dbhin&quot; , &quot;harvest_activity_name_1&quot; , &quot;harvest_year_id_1&quot; ) , row.numbers = FALSE , feature.id = FALSE ) ) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
