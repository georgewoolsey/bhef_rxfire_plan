# Analyze Lidar Data {#stem_map}

```{r, include=FALSE, warning=F, message=F}
# data mgmt
library(tidyverse)
library(lubridate)
# visualization
library(RColorBrewer)
library(scales)
library(ggrepel)
library(viridis)
library(kableExtra)
# spatial
library(sf)
library(lwgeom) 
library(mapview) #Interactive maps
library(leafpop) #map html popup
library(lidR) # lidar data
library(elevatr) # elevation data (DEMs)
# library(spatstat) #point pattern analysis


```

```{r, warning=F, message=F, results='hide'}
# turn off the s2 processing 
## https://stackoverflow.com/questions/68478179/how-to-resolve-spherical-geometry-failures-when-joining-spatial-data
sf::sf_use_s2(FALSE)
```

## Download Data From Nat'l Map

The [USGS National Map](https://apps.nationalmap.gov/downloader/) was used to obtain a list of file download links for "Elevation Source Data (3DEP) - Lidar, IfSAR" data available marked as "Lidar Point Cloud (LPC)". This download file list was placed in the `data` folder where the code below utilizes it to download data. The "thumbnail" option in the Nat'l Map was used to determine that the "Fugro" data will suffice to cover the BHEF area. Also, downloaded NAIP imagery while had ROI drawn in Nat'l Map.

```{r, warning=F, message=F, results='hide', fig.width = 10, fig.height = 6}
#######################################################
#######################################################
# lidar data
#######################################################
#######################################################

# open download text file
urls <- read.delim("../data/usgs_lidar_data.txt", header = FALSE) %>% 
  dplyr::rename(url_path = 1) %>% 
  dplyr::filter(grepl("FUGRO", toupper(url_path)) == TRUE) %>%
  dplyr::mutate(
    orig_fname = word(gsub("/", " ", url_path), -1)
    , fname_sans_typ = gsub(".laz", "", orig_fname)
  )


# create parent directory for data
  hey_dir <- "../data/lidar/"
  if(dir.exists(hey_dir)==FALSE){
    dir.create(hey_dir)
  }
#loop through to download lidar data
  for(i in 1:nrow(urls)){
    # set up names
    f_nm <- paste0(hey_dir
      , urls$orig_fname[i]
    )
    options(timeout = 60 * 15)
    ########################
    ## download and unzip
    ########################
    if(file.exists(f_nm)==FALSE){
      # download
      download.file(urls$url_path[i], destfile = f_nm)
    }else{
      print(paste0(f_nm, " file already exists"))
    }
  }
```

NAIP imagery was downloaded from the [USGS Earth Explorer](https://earthexplorer.usgs.gov/).

```{r, warning=F, message=F, results='hide', fig.width = 10, fig.height = 6}
## Load NAIP Imagery

# load with stars
tifs <- list.files("../data/naip/", pattern = "\\.tif$", full.names = TRUE)

# x <- stars::read_stars(imgs[1])
x <- stars::read_stars(tifs[1])
plot(x %>% dplyr::slice(band, 1), axes = TRUE)

r = stars::st_rgb(x[,,,c(1:3)], use_alpha = FALSE)

# ggplot() + 
#   stars::geom_stars(data = r) +
#   scale_fill_identity()

```

## Load Vector Data

Spatial data was loaded and cleaned in [prior chapter](#vector_data). 

```{r, warning=F, message=F, results='hide', fig.width = 10, fig.height = 6}
# save cleaned data for reading to R later
forests_bhnf <- sf::st_read("../data/forests_bhnf.gpkg")
bhef_boundary <- sf::st_read("../data/bhef_boundary.gpkg")
bhef_harvests <- sf::st_read("../data/bhef_harvests.gpkg")
research_plots <- sf::st_read("../data/research_plots.gpkg")
stem_map <- sf::st_read("../data/stem_map.gpkg")
```

## Load Elevation Data

Using `elevatr::get_elev_raster` to get a digital elevation model (DEM) raster (~6.8m resolution).

```{r, warning=F, message=F, results='hide', fig.width = 10, fig.height = 6}
# read in elevation data
# z =14 is highest resolution (~6.8m)
if(file.exists("../data/bhef_elev.tif") == FALSE){
  elev <- elevatr::get_elev_raster(bhef_boundary, z = 14)
  # sf::st_crs(elev) == sf::st_crs(bhef_boundary)
  bhef_elev <- stars::st_as_stars(elev)
    # sf::st_transform(crs = sf::st_crs(bhef_boundary))
  # save
  stars::write_stars(bhef_elev, "../data/bhef_elev.tif", append = FALSE)
}else{
  bhef_elev <- stars::read_stars("../data/bhef_elev.tif")
}

# plot
ggplot() + stars::geom_stars(data = bhef_elev[bhef_boundary]) +
  scale_fill_viridis_c(option = "cividis", alpha = 0.9, na.value = "transparent") +
  labs(
      title = "BHEF Elevation Map"
      , subtitle = sf::st_crs(bhef_elev)$input
    ) +
  theme_bw() +
  guides(
    fill = guide_legend(title="elev. (m)")
  )

```

```{r, warning=F, message=F, echo=FALSE, include=FALSE}
remove(list = c("urls", "elev", "f_nm", "hey_dir", "tifs"))
gc()
```

## Load Lidar Data

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
# list laz files
  lazs <- list.files("../data/lidar/", pattern = "\\.laz$", full.names = TRUE)
# change projection of DEM  
  bhef_elev_reproj <- bhef_elev %>% stars::st_warp(crs = sf::st_crs( lidR::readLAS(lazs[1], select = "xyz") ))
######################################################
# read laz files
######################################################
  # If several files are read at once the returned LAS object is considered as one LAS file.
  # las <- lidR::readLAS(c(lazs[1],lazs[2]), select = "xyz")  # load XYZ only
  las <- lidR::readLAS(lazs[2], select = "xyz")  # load XYZ only
  # lidR::las_check(las)
  # remove duplicate points
  las <- lidR::filter_duplicates(las)
  # lidR::las_check(las)
  # summary(las$Z)
  # sf::st_crs(las)
  # temp_plot <- plot(las, color = "Z", breaks = "quantile", bg = "white")
  # temp_plot
  # # add_treetops3d(temp_plot, ttops)
######################################################
# remove outliers
######################################################
  # Use Statistical Outliers Removal (SOR)
    # k = number of neighbors
    # m = multiplier in : avg distance + m * std deviation
    las <- lidR::classify_noise(las, sor(k = 15, m = 7))
    # plot(las, color = "Classification", bg = "white", size = 3)
  # Remove outliers using filter_poi()
    las <- lidR::filter_poi(las, Classification != LASNOISE)
    # plot(las, color = "Z", breaks = "quantile", bg = "white")
  # #repeat process with Isolated Voxels Filter IVF
  #   las <- lidR::classify_noise(las, ivf(res = 5, n = 6))
  #   # plot(las, color = "Classification", bg = "white", size = 3)
  # # Remove outliers using lidR::filter_poi()
  #   las <- lidR::filter_poi(las, Classification != LASNOISE)
    # plot(las, color = "Z", breaks = "quantile", bg = "white")
# #####################################################
# Ground classification
# !!!!!!!!!!!!!!!!!!!!!!!!!! This is computationally intensive :'(
# #####################################################
# ##################################################
# Progressive Morphological Filter The implementation of PMF algorithm in lidR
# is based on the method described in Zhang et al. (2003)
# ##################################################
# # # b numeric. This is the parameter b in Zhang et al. (2003) (eq. 4 and 5).
# # # dh0 numeric. This is dh0 in Zhang et al. (2003) (eq. 7).
# # # dhmax numeric. This is dhmax in Zhang et al. (2003) (eq. 7).
# # # s numeric. This is s in Zhang et al. (2003) (eq. 7).
# # # max_ws numeric. Maximum window size to be used in filtering ground returns. This
# # # limits the number of windows created.
# # # exp logical. The window size can be increased linearly or exponentially (eq. 4 or 5).
# # lidR::util_makeZhangParam(
# #   b = 2,
# #   dh0 = 0.2,
# #   dhmax = 210,
# #   s = 1.2,
# #   max_ws = 20,
# #   exp = FALSE
# # )
# las <- lidR::classify_ground(las, algorithm = pmf(
#   ws = lidR::util_makeZhangParam()$ws
#   , th = lidR::util_makeZhangParam()$th
#   )
# )
######################################################
# Height normalization using DEM 
    # could create own DEM with lidar data ... 
    # but will use out of the box product for now
######################################################
  # subtract DEM from lidar returns
    nlas <- las - bhef_elev_reproj
  # correct for below ground returns
    # nlas@data$Z <- ifelse(ceiling(nlas@data$Z) == 0 | floor(nlas@data$Z) == 0, 0, nlas@data$Z)
    # nlas <- filter_poi(nlas, Z >= 0) # remove below ground points
    nlas@data$Z <- ifelse(nlas@data$Z <= 0, 0, nlas@data$Z)
  # update classification
    nlas@data$Classification <- ifelse(nlas@data$Z==0, 2, nlas@data$Classification)
    # nlas <- filter_poi(nlas, Z <= quantile(nlas@data[which(Classification==1),]$Z, .9995) )
    # plot(nlas, color = "Z", breaks = "pretty", bg = "white")
    # plot(lidR::filter_ground(nlas), color = "Classification", bg = "white")
    # summary(nlas$Z)
    # table(nlas$Classification)
# ######################################################
# # Height normalization using point cloud interpolation
# # !!!!!! must run ground classification above first
# ######################################################
#   # point cloud normalization using interpolation
#     nlas <- normalize_height(las, knnidw())
#     # plot(nlas, color = "Z", breaks = "pretty", bg = "white")
#     # plot(lidR::filter_ground(nlas), color = "Classification", bg = "white")
#     # summary(nlas$Z)
#     # table(nlas$Classification)
######################################################
# Canopy Height model
######################################################
  chm <- lidR::rasterize_canopy(
      nlas
      , res = 1
      , p2r(subcircle = 0.0
            # , na.fill = tin()
            , na.fill = knnidw(
              k = 10
              , p = 2
              , rmax = 5
            )
        )
    )
  # chm_df <- as.data.frame(chm, xy = TRUE)
  # plot
  col <- rev( brewer.pal(n = 11, "RdYlBu") ) # height.colors(20)
  plot(chm, col = col, bg = "white")
  # fill na's and smooth the CHM with the "raster" package
  w <- matrix(1, 3, 3)
  smoothed <- focal(chm, w, fun = mean, na.rm = TRUE)
  col <- rev( brewer.pal(n = 11, "RdYlBu") ) # height.colors(20)
  plot(smoothed, col = col, bg="white"
       , main = "Canopy Height Model based on aerial imagery collected Sept. 1957\nWilm & Dunford (1948) Experimental Plot Area\nFraser Experimental Forest"
       , xlab = "UTM Easting Coordinate (m)"
       , ylab = "UTM Northing Coordinate (m)"
       , legend=FALSE
  )
  plot(smoothed, col = col, bg="white"
       , legend.only=TRUE,
       legend.width=1, legend.shrink=0.75,
       legend.args=list(text='Height (m)', side=4, font=2, line=2.5, cex=0.8)
  )
  
  hist(nlas@data[which(Classification==1),]$Z
       , breaks = seq(0, round(max(nlas@data[which(Classification==1),]$Z))+round(sd(nlas@data[which(Classification==1),]$Z), round(sd(nlas@data[which(Classification==1),]$Z))))
       , main = "Distribution of normalized non-ground point heights"
       , xlab = "Height (m)")


```

## Map Harvests, Research Plots, Stem Map

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
# make map
# different background map types: https://leaflet-extras.github.io/leaflet-providers/preview/
# names(leaflet.providers::providers_loaded()$providers)
mapviewOptions(homebutton = FALSE, basemaps = c("Esri"))
# map
mapview(bhef_boundary
        , color = "black"
        , lwd = 3
        , alpha.regions = 0
        , label = FALSE
        , legend = FALSE
        , popup = FALSE
) +
mapview(bhef_harvests_l15
        , zcol = "treatment_type_grp"
        , col.regions = viridis::viridis(n=length(unique(bhef_harvests_l15$treatment_type_grp)))
        , alpha.regions = 0.6
        , label = c("lab")
        , legend = FALSE
          , popup = popupTable(
              bhef_harvests_l15
              , zcol = c(
                "year_id"
                , "treatment_type_grp"
                , "activity_name"
              )
              , row.numbers = FALSE
              , feature.id = FALSE
            )
) +
mapview(research_plots
        , zcol = "trt"
        , col.regions = viridis::mako(n=length(unique(research_plots$trt)), direction = -1)
        , lwd = 2
        , col = "gray90"
        , alpha.regions = 0.8
        , label = c("trt")
        , legend = FALSE
          , popup = popupTable(
              research_plots
              , zcol = c(
                "plot"
                , "trt"
                , "harvest_activity_name_1"
                , "harvest_year_id_1"
              )
              , row.numbers = FALSE
              , feature.id = FALSE
            )
)  +
mapview(stem_map
  , zcol = "unit"
  , col.regions = viridis::turbo(n=length(unique(stem_map$unit)), alpha = 0.8)
    # RColorBrewer::brewer.pal(n = length(unique(stem_map$unit)), name = "RdYlBu")
  , cex = 3.5
  , label = c("unit")
  , legend = FALSE
    , popup = popupTable(
        stem_map
        , zcol = c(
          "unit"
          , "plot"
          , "species"
          , "tag"
          , "heightft"
          , "dbhin"
          , "harvest_activity_name_1"
          , "harvest_year_id_1"
        )
        , row.numbers = FALSE
        , feature.id = FALSE
      )
)

```

*Note, only harvests in last 15 years shown*

## Write Out Data

Make a map of the stem mapped trees.

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
# save cleaned data for reading to R later
sf::st_write(forests_bhnf, "../data/forests_bhnf.gpkg", append = FALSE)
sf::st_write(bhef_boundary, "../data/bhef_boundary.gpkg", append = FALSE)
sf::st_write(bhef_harvests, "../data/bhef_harvests.gpkg", append = FALSE)
sf::st_write(research_plots, "../data/research_plots.gpkg", append = FALSE)
sf::st_write(stem_map, "../data/stem_map.gpkg", append = FALSE)
```
