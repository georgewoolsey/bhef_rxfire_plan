# Analyze Lidar Data {#stem_map}

```{r, include=FALSE, warning=F, message=F}
# data mgmt
library(tidyverse)
library(lubridate)
# visualization
library(RColorBrewer)
library(scales)
library(ggrepel)
library(viridis)
library(kableExtra)
# spatial
library(sf)
library(stars)
library(lwgeom) 
library(mapview) #Interactive maps
library(leafpop) #map html popup
library(lidR) # lidar data
library(elevatr) # elevation data (DEMs)
library(terra) # raster math
# library(spatstat) #point pattern analysis


```

```{r, warning=F, message=F, results='hide'}
# turn off the s2 processing 
## https://stackoverflow.com/questions/68478179/how-to-resolve-spherical-geometry-failures-when-joining-spatial-data
sf::sf_use_s2(FALSE)
```

## Download Data From Nat'l Map

The [USGS National Map](https://apps.nationalmap.gov/downloader/) was used to obtain a list of file download links for "Elevation Source Data (3DEP) - Lidar, IfSAR" data available marked as "Lidar Point Cloud (LPC)". This download file list was placed in the `data` folder where the code below utilizes it to download data. The "thumbnail" option in the Nat'l Map was used to determine that the "Fugro" data will suffice to cover the BHEF area. Also, downloaded NAIP imagery while had ROI drawn in Nat'l Map.

```{r, warning=F, message=F, results='hide', fig.width = 10, fig.height = 6}
#######################################################
#######################################################
# lidar data
#######################################################
#######################################################

# open download text file
urls <- read.delim("../data/usgs_lidar_data.txt", header = FALSE) %>% 
  dplyr::rename(url_path = 1) %>% 
  dplyr::filter(grepl("FUGRO", toupper(url_path)) == TRUE) %>%
  dplyr::mutate(
    orig_fname = word(gsub("/", " ", url_path), -1)
    , fname_sans_typ = gsub(".laz", "", orig_fname)
  )


# create parent directory for data
  hey_dir <- "../data/lidar/"
  if(dir.exists(hey_dir)==FALSE){
    dir.create(hey_dir)
  }
#loop through to download lidar data
  for(i in 1:nrow(urls)){
    # set up names
    f_nm <- paste0(hey_dir
      , urls$orig_fname[i]
    )
    options(timeout = 60 * 15)
    ########################
    ## download and unzip
    ########################
    if(file.exists(f_nm)==FALSE){
      # download
      download.file(urls$url_path[i], destfile = f_nm)
    }else{
      print(paste0(f_nm, " file already exists"))
    }
  }
```

NAIP imagery was downloaded from the [USGS Earth Explorer](https://earthexplorer.usgs.gov/).

```{r, warning=F, message=F, results='hide', fig.width = 10, fig.height = 6}
## Load NAIP Imagery

# load with stars
tifs <- list.files("../data/naip/", pattern = "\\.tif$", full.names = TRUE)

# x <- stars::read_stars(imgs[1])
x <- stars::read_stars(tifs[1])
plot(x %>% dplyr::slice(band, 1), axes = TRUE)

r = stars::st_rgb(x[,,,c(1:3)], use_alpha = FALSE)

# ggplot() + 
#   stars::geom_stars(data = r) +
#   scale_fill_identity()

```

## Load Vector Data

Spatial data was loaded and cleaned in [prior chapter](#vector_data). 

```{r, warning=F, message=F, results='hide', fig.width = 10, fig.height = 6}
# save cleaned data for reading to R later
forests_bhnf <- sf::st_read("../data/forests_bhnf.gpkg")
bhef_boundary <- sf::st_read("../data/bhef_boundary.gpkg")
bhef_harvests <- sf::st_read("../data/bhef_harvests.gpkg")
research_plots <- sf::st_read("../data/research_plots.gpkg")
stem_map <- sf::st_read("../data/stem_map.gpkg")
```

## Load Elevation Data

Using `elevatr::get_elev_raster` to get a digital elevation model (DEM) raster (~6.8m resolution).

```{r, warning=F, message=F, results='hide', fig.width = 10, fig.height = 6}
# read in elevation data
# z =14 is highest resolution (~6.8m)
if(file.exists("../data/bhef_elev.tif") == FALSE){
  elev <- elevatr::get_elev_raster(bhef_boundary, z = 14)
  # sf::st_crs(elev) == sf::st_crs(bhef_boundary)
  bhef_elev <- stars::st_as_stars(elev)
    # sf::st_transform(crs = sf::st_crs(bhef_boundary))
  # save
  stars::write_stars(bhef_elev, "../data/bhef_elev.tif", append = FALSE)
}else{
  bhef_elev <- stars::read_stars("../data/bhef_elev.tif")
}

# plot
ggplot() + stars::geom_stars(data = bhef_elev[bhef_boundary]) +
  scale_fill_viridis_c(option = "cividis", alpha = 0.9, na.value = "transparent") +
  labs(
      title = "BHEF Elevation Map"
      , subtitle = sf::st_crs(bhef_elev)$input
    ) +
  theme_bw() +
  theme(
    axis.text = element_text(size = 8)
  ) +
  guides(
    fill = guide_legend(title="Elev. (m)")
  )

```

```{r, warning=F, message=F, echo=FALSE, include=FALSE}
remove(list = c("urls", "elev", "f_nm", "hey_dir", "tifs", "r", "x"))
gc()
```

## Load Lidar Data

Use the `lidR` package for manipulating and visualizing point cloud data. See the very [helpful book](https://r-lidar.github.io/lidRbook/index.html) by Roussel, J.R., Goodbody, T.R.H., and Tompalski P. (2021) for more information.

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
# list laz files
  lazs <- list.files("../data/lidar/", pattern = "\\.laz$", full.names = TRUE)
# change projection of DEM 
  # # creating a new regular grid in a new CRS
  # newgrid <- bhef_boundary %>% 
  #   sf::st_transform(crs = sf::st_crs( lidR::readLAS(lazs[1], select = "xyz") )) %>% 
  #   sf::st_bbox() %>%
  #   stars::st_as_stars()
  # # set up old grid to warp back
  # oldgrid <- bhef_boundary %>% 
  #   sf::st_bbox() %>%
  #   stars::st_as_stars()
  # # warping the old raster to the new grid
  # bhef_elev_reproj <- bhef_elev %>%
  #   stars::st_warp(newgrid)
  
  bhef_elev_reproj <- bhef_elev %>% stars::st_warp(crs = sf::st_crs( lidR::readLAS(lazs[1], select = "xyz") ))
######################################################
# read laz files
######################################################
  # If several files are read at once the returned LAS object is considered as one LAS file.
  # las <- lidR::readLAS(c(lazs[1],lazs[2]), select = "xyz")  # load XYZ only
  las <- lidR::readLAS(lazs[2], select = "xyz")  # load XYZ only
  # lidR::las_check(las)
  # remove duplicate points
  las <- lidR::filter_duplicates(las)
  # lidR::las_check(las)
  # summary(las$Z)
  # sf::st_crs(las)
  # temp_plot <- plot(las, color = "Z", breaks = "quantile", bg = "white")
  # temp_plot
  # # add_treetops3d(temp_plot, ttops)
######################################################
# remove outliers
######################################################
  # Use Statistical Outliers Removal (SOR)
    # k = number of neighbors
    # m = multiplier in : avg distance + m * std deviation
    las <- lidR::classify_noise(las, sor(k = 15, m = 7))
    # plot(las, color = "Classification", bg = "white", size = 3)
  # Remove outliers using filter_poi()
    las <- lidR::filter_poi(las, Classification != LASNOISE)
    # plot(las, color = "Z", breaks = "quantile", bg = "white")
  # #repeat process with Isolated Voxels Filter IVF
  #   las <- lidR::classify_noise(las, ivf(res = 5, n = 6))
  #   # plot(las, color = "Classification", bg = "white", size = 3)
  # # Remove outliers using lidR::filter_poi()
  #   las <- lidR::filter_poi(las, Classification != LASNOISE)
    # plot(las, color = "Z", breaks = "quantile", bg = "white")
# #####################################################
# Ground classification
# !!!!!!!!!!!!!!!!!!!!!!!!!! This is computationally intensive :'(
# #####################################################
# ##################################################
# Progressive Morphological Filter The implementation of PMF algorithm in lidR
# is based on the method described in Zhang et al. (2003)
# ##################################################
# # # b numeric. This is the parameter b in Zhang et al. (2003) (eq. 4 and 5).
# # # dh0 numeric. This is dh0 in Zhang et al. (2003) (eq. 7).
# # # dhmax numeric. This is dhmax in Zhang et al. (2003) (eq. 7).
# # # s numeric. This is s in Zhang et al. (2003) (eq. 7).
# # # max_ws numeric. Maximum window size to be used in filtering ground returns. This
# # # limits the number of windows created.
# # # exp logical. The window size can be increased linearly or exponentially (eq. 4 or 5).
# # lidR::util_makeZhangParam(
# #   b = 2,
# #   dh0 = 0.2,
# #   dhmax = 210,
# #   s = 1.2,
# #   max_ws = 20,
# #   exp = FALSE
# # )
# las <- lidR::classify_ground(las, algorithm = pmf(
#   ws = lidR::util_makeZhangParam()$ws
#   , th = lidR::util_makeZhangParam()$th
#   )
# )
```

### Height normalization using DEM 

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
######################################################
# Height normalization using DEM 
    # could create own DEM with lidar data ... 
    # but will use out of the box product for now
######################################################
  # subtract DEM from lidar returns
    nlas <- las - bhef_elev_reproj
  # correct for below ground returns
    nlas@data$Z <- ifelse(
        ceiling(nlas@data$Z) == 0 
        | floor(nlas@data$Z) == 0
        | nlas@data$Z <= 0
      , 0, nlas@data$Z
    )
    # nlas <- filter_poi(nlas, Z >= 0) # remove below ground points
    nlas@data$Z <- ifelse(nlas@data$Z <= 0, 0, nlas@data$Z)
  # update classification
    nlas@data$Classification <- ifelse(nlas@data$Z==0, 2, nlas@data$Classification)
  # filter out top 0.2% heights
    nlas <- filter_poi(nlas, Z <= stats::quantile((nlas@data %>% dplyr::filter(Classification==1))$Z, 0.998))
    # plot(nlas, color = "Z", breaks = "pretty", bg = "white")
    # summary(nlas$Z)
    # table(nlas$Classification)
# ######################################################
# # Height normalization using point cloud interpolation
# # !!!!!! must run ground classification above first
# ######################################################
#   # point cloud normalization using interpolation
#     nlas <- normalize_height(las, knnidw())
#     # plot(nlas, color = "Z", breaks = "pretty", bg = "white")
#     # plot(lidR::filter_ground(nlas), color = "Classification", bg = "white")
#     # summary(nlas$Z)
#     # table(nlas$Classification)
    
# descriptive stats
kable(nlas@data %>% 
        dplyr::group_by(
          Classification
        ) %>% 
        dplyr::summarise(
          # plots = dplyr::n_distinct(plot)
          points = dplyr::n()
          , min_z = min(Z)
          , max_z = max(Z)
          , mean_z = mean(Z)
          , median_z = median(Z)
          , stdev_z = sd(Z)
        ) %>% 
    dplyr::arrange(Classification) %>% 
    dplyr::mutate(
      Classification = dplyr::case_when(
        Classification == 1 ~ "Surface"
        , Classification == 2 ~ "Ground"
        , TRUE ~ "Other"
      )
    )
  , format = "html" 
  , caption = "Point Cloud Summary Statistics for Return Height (Z)"
  , digits = 1
  , col.names = c(
    "Classification"
    , "points"
    , "min"
    , "max"
    , "mean"
    , "median"
    , "st.dev."
  )
  , align=rep('c', 5)
) %>% 
# kable_classic() %>%
add_header_above(c(" " = 2, "Point Return Height (m)" = 5)) %>% 
kable_material(c("striped", "hover")) %>%
# column_spec(., 2, width = "20em") %>% 
kable_styling(font_size = 11) 
    
# ggplot() + geom_histogram(data = (nlas@data %>% dplyr::filter(Classification == 1)), aes(Z), binwidth = 1)
```

### Canopy Height model

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
######################################################
# Canopy Height model
######################################################
    chm <- lidR::rasterize_canopy(
      nlas
      , res = 1
      , p2r(subcircle = 0.0
            # , na.fill = tin()
            , na.fill = knnidw(
              k = 10
              , p = 2
              , rmax = 5
            )
        )
      , pkg = "terra"
    ) 
    
    # smooth chm pixels with median value in 3x3 matrix
    kernel <- matrix(1,3,3)
    chm_smooth <- terra::focal(chm, w = kernel, fun = median, na.rm = TRUE) %>% 
      stars::st_as_stars() %>%
      stars::st_warp(crs = sf::st_crs(bhef_boundary)) 
    # %>% 
    #   sf::st_transform(crs = sf::st_crs(bhef_boundary))
    # non smoothed
    chm <- chm %>% 
      stars::st_as_stars() %>%
      stars::st_warp(crs = sf::st_crs(bhef_boundary))
    
  # plot
  ggplot() +
    stars::geom_stars(data = chm_smooth %>% dplyr::filter(values >=2)) +
    geom_sf(data = sf::st_crop(bhef_boundary, sf::st_bbox(chm_smooth)), alpha = 0, lwd = 0) +
    scale_fill_viridis_c(option = "mako", alpha = 0.9) +
    labs(
      title = "BHEF Canopy Height Model"
      , subtitle = sf::st_crs(chm_smooth)$input
    ) +
    theme_bw() +
    theme(
      # legend.position = "bottom"
      # , legend.direction = "horizontal"
      axis.text = element_text(size = 8)
    ) +
    guides(
      fill = guide_legend(title="Hgt. (m)")
    )  

xxx <- chm_smooth %>% 
  # create classes based on Steel et al. 2021
  dplyr::mutate(
    veg_class = dplyr::case_when(
      values > 8 ~ 3 # canopy
      , values >= 2 ~ 2 # subcanopy
      , values >= 1 ~ 1 # understory
      , TRUE ~ 0 # ground
    )
  ) %>% 
  merge() %>% 
  setNames("z") %>%
  st_set_dimensions(names = c("x", "y", "band")) %>% 
  # select only the class band
  dplyr::slice(band, 2) %>% 
  # convert to vector data and merge polygons with identical values
  sf::st_as_sf(as_points = FALSE, merge = TRUE) %>% 
  # transform to same crs as rest of data
  sf::st_transform(crs = st_crs(bhef_boundary)) 

names(xxx)[1] = "veg_class"

ggplot() + 
  geom_sf(data = xxx, aes(fill = as.factor(veg_class)), lwd = 0 ) + 
  scale_fill_viridis_d() + 
  theme_bw()
  

  
```

### Individual Tree Detection (ITD)

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
######################################################
# Individual Tree Detection (ITD)
######################################################
# local maximum filtering (LMF) with variable window size
  # points below 2 m will equate to a window size of 3 m, 
    # while points above 20 meters equate to a window size of 5 m. 
    # Anything between 2 and 20 meter will have a non-linear relationship
  # define variable window function
  ws_fn <- function(x) {
      y <- 2.6 * (-(exp(-0.08*(x-2)) - 1)) + 3
      y[x < 2] <- 3
      y[x > 20] <- 5
      return(y)
  }
  # ITD on CHM
  ttops <- lidR::locate_trees(chm_smooth, lmf(ws = ws_fn))
    
  # plot
  ggplot() +
    stars::geom_stars(data = chm_smooth) +
    geom_sf(data = ttops, color = viridis::viridis(n=1, direction = -1), alpha = 0.7, shape = ".") +
    scale_fill_viridis_c(option = "mako", alpha = 0.9) +
    labs(
      title = "BHEF Canopy Height Model with Tree Tops Identified (yellow)"
      , subtitle = sf::st_crs(chm_smooth)$input
    ) +
    theme_bw() +
    theme(
      axis.text = element_text(size = 8)
    ) +
    guides(
      fill = guide_legend(title="Hgt. (m)")
    )
  
  # height range of tree tops
  # !!!!!!!!!!!!!!!!!!make hist
  
  # hey_plot <- plot(nlas, color = "Z", breaks = "pretty", bg = "white")
  # add_treetops3d(hey_plot, ttops <- lidR::locate_trees(chm_smooth, lmf(ws = ws_fn)), col = "black")
  # ?lidR::pixel_metrics()
```

### Individual Tree Segmentation (ITS)

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
######################################################
# Individual Tree Segmentation (ITS)
######################################################
algo <- lidR::dalponte2016(chm_smooth, ttops)
crowns <- algo()

plot(crowns, col = pastel.colors(200))
# 
# # plot
#   ggplot() +
#     stars::geom_stars(data = crowns) +
#     geom_sf(data = ttops, color = viridis::viridis(n=1, direction = -1), alpha = 0.7, shape = ".") +
#     # scale_fill_viridis_c(option = "turbo", alpha = 0.7) +
#     labs(
#       title = "BHEF Individual Tree Crowns (tree tops in yellow)"
#       , subtitle = sf::st_crs(crowns)$input
#     ) +
#     theme_bw() +
#     theme(
#       legend.position = "none"
#       , axis.text = element_text(size = 8)
#     )
  


```


```{r, warning=F, message=FALSE, eval=FALSE, include=FALSE}
# apply itd to smoothed kernel chm?
  methods(class = "stars")


# polygon_list = list(rbind(c(-1, 1), c(-1, -1), c(1, -1), c(1, 1), c(-1, 1)))
  polygon_list = list(rbind(
    # c(x, y, z)
    c(sf::st_bbox(bhef_boundary)[1], sf::st_bbox(bhef_boundary)[4]) # upper left
    , c(sf::st_bbox(bhef_boundary)[1], sf::st_bbox(bhef_boundary)[2]) # lower left
    , c(sf::st_bbox(bhef_boundary)[3], sf::st_bbox(bhef_boundary)[2]) # lower right
    , c(sf::st_bbox(bhef_boundary)[3], sf::st_bbox(bhef_boundary)[4]) # upper right
    , c(sf::st_bbox(bhef_boundary)[1], sf::st_bbox(bhef_boundary)[4]) # upper left
    )
  )
  hey_box <- sf::st_polygon(polygon_list) %>% sf::st_sfc(crs = sf::st_crs(bhef_boundary))
  
  ggplot() + 
    geom_sf(data = hey_box, fill = "transparent", lwd = 2, color = "red") + 
    stars::geom_stars(data = bhef_elev[bhef_boundary]) +
    scale_fill_viridis_c(option = "cividis", alpha = 0.9, na.value = "transparent") +
    theme_bw()
  
  
```

## Map Harvests, Research Plots, Stem Map

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
# make map
# different background map types: https://leaflet-extras.github.io/leaflet-providers/preview/
# names(leaflet.providers::providers_loaded()$providers)
mapviewOptions(homebutton = FALSE, basemaps = c("Esri"))
# map
mapview(bhef_boundary
        , color = "black"
        , lwd = 3
        , alpha.regions = 0
        , label = FALSE
        , legend = FALSE
        , popup = FALSE
) +
mapview(bhef_harvests_l15
        , zcol = "treatment_type_grp"
        , col.regions = viridis::viridis(n=length(unique(bhef_harvests_l15$treatment_type_grp)))
        , alpha.regions = 0.6
        , label = c("lab")
        , legend = FALSE
          , popup = popupTable(
              bhef_harvests_l15
              , zcol = c(
                "year_id"
                , "treatment_type_grp"
                , "activity_name"
              )
              , row.numbers = FALSE
              , feature.id = FALSE
            )
) +
mapview(research_plots
        , zcol = "trt"
        , col.regions = viridis::mako(n=length(unique(research_plots$trt)), direction = -1)
        , lwd = 2
        , col = "gray90"
        , alpha.regions = 0.8
        , label = c("trt")
        , legend = FALSE
          , popup = popupTable(
              research_plots
              , zcol = c(
                "plot"
                , "trt"
                , "harvest_activity_name_1"
                , "harvest_year_id_1"
              )
              , row.numbers = FALSE
              , feature.id = FALSE
            )
)  +
mapview(stem_map
  , zcol = "unit"
  , col.regions = viridis::turbo(n=length(unique(stem_map$unit)), alpha = 0.8)
    # RColorBrewer::brewer.pal(n = length(unique(stem_map$unit)), name = "RdYlBu")
  , cex = 3.5
  , label = c("unit")
  , legend = FALSE
    , popup = popupTable(
        stem_map
        , zcol = c(
          "unit"
          , "plot"
          , "species"
          , "tag"
          , "heightft"
          , "dbhin"
          , "harvest_activity_name_1"
          , "harvest_year_id_1"
        )
        , row.numbers = FALSE
        , feature.id = FALSE
      )
)

```

*Note, only harvests in last 15 years shown*

## Write Out Data

Make a map of the stem mapped trees.

```{r, warning=F, message=F, fig.width = 10, fig.height = 6}
# save cleaned data for reading to R later
sf::st_write(forests_bhnf, "../data/forests_bhnf.gpkg", append = FALSE)
sf::st_write(bhef_boundary, "../data/bhef_boundary.gpkg", append = FALSE)
sf::st_write(bhef_harvests, "../data/bhef_harvests.gpkg", append = FALSE)
sf::st_write(research_plots, "../data/research_plots.gpkg", append = FALSE)
sf::st_write(stem_map, "../data/stem_map.gpkg", append = FALSE)
```
